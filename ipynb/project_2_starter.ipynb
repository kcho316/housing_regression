{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** You probably will see warnings. These are not errors! However, you should read them and try to understand why they're there. Can you fix them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://rentinginla.com/wp-content/uploads/2015/12/Buying.jpg)\n",
    "# [Project 2: Predicting House Prices with Advanced Regression Techniques](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "The goal of this project is for you to use EDA, visualization, data cleaning, preprocesing, and linear models to predict home prices given the features of the home, and interpret your linear models to find out what features add value to a home! This project is a bit more open-ended than project 1. \n",
    "\n",
    "Be sure to ...\n",
    "\n",
    "* Think about your choices when it comes to your choices about the data. Be ready to defend your decisions!\n",
    "* Use lots of plots to dig deeper into the data! Describe the plots and convey what you learned from them.\n",
    "* Don't forget to read the [description of the data](../data_description.txt) (also available at the kaggle website)! This has valuable information that will help you clean and impute data. `NaN` means something in many of the columns! Don't just drop or fill them!\n",
    "* Try fitting many models! Document your work and note what you've tried.\n",
    "* Apply what you've learned in class, books, videos, Kaggle forums, and blog posts. There have been a TON of blog posts about this;  you should seek them out and read them!\n",
    "\n",
    "\n",
    "From the Kaggle competition website:\n",
    "\n",
    "    Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "    With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data \n",
    "\n",
    "* The data comes in three separate CSVs located in `../data/`. \n",
    "* Load the CSV into a `DataFrame`. \n",
    "* Make sure to check the `.head` or `.sample`. How many rows? How many columns?\n",
    "* Familiarize yourself with the column names and what they represent.\n",
    "* Is there a column that can be set as the `index`? If so, set that column as the index when loading the data. (`df.set_index()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus:** Write an assertion statement to programmatically verify the correct number of rows and columns were imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Data Types\n",
    "\n",
    "Read the data description on Kaggle. Which variables are numerical and categorical? Are there any columns that can be deleted? \n",
    "\n",
    "Make sure the `dtype` of each column is correct. \n",
    "\n",
    "**NOTE:** There is one column in particular that should be categorical but will load in pandas as numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Plot histograms of the numeric columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Plot the Numeric Columns Against `SalePrice` using scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Use bar plots to plot categorical features against `SalePrice`. \n",
    "\n",
    "**HINT:** Look up how to create bar plots in `matplotlib`. You will have to transform the data before you can create a bar plot! Also, look up [how to plot error bars](https://pandas.pydata.org/pandas-docs/stable/visualization.html#plotting-with-error-bars) so you can also observe the variability in your data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Identify and Remove Outliers for `SalePrice`\n",
    "\n",
    "Make sure to... \n",
    "* Plot a histogram of the housing price. \n",
    "* Supply a definition of what an outlier is by your criteria. Does Tukey's method make sense with 1.5 times the interquartile range, or should that range be increased or decreased?\n",
    "* Use masking to remove the outliers as you've defined them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Fill missing data!\n",
    "\n",
    "* How many null values are in each column? Make a bar plot showing this only for columns with missing data.\n",
    "* For each column with nulls, do nulls represent anything? Read the data description.\n",
    "  * Some columns that are appearing as _null_ might legitimately be known (ie: \"na\").  Double check the [data description](../data_description.txt) for proper value representation.  A feature might actually be better represented by \"not available\" or \"na\" rather than `NULL` or `NaN`.  There's a difference between `NULL` (unknown), and \"NA\" (not available).  It might mean the difference between \"there isn't a garage\" and \"there is no garage data\". \n",
    "* Fill null values for each column by imputation. Here are some common methods for imputation:\n",
    "  1. Using domain knowledge to select an appropriate value.\n",
    "  1. Value from a randomly selected row.\n",
    "  2. Mean, median, or mode value of the series.\n",
    "  3. Value estimated by a predictive model.\n",
    "* Make sure to justify your method for filling null values.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that you have *truly* eliminated all the null values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Create dummy variables for categorical columns\n",
    "\n",
    "Use `pd.get_dummies()` to turn your categorical features into numeric features. Make sure there are **no null values** in your dataset before you do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Split your data into a train and test set.\n",
    "\n",
    "* Use `train_test_split` to hold out a test set. \n",
    "* Why do we hold out a test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hold out a test set because we need to understand how our model performs on data it hasn't seen. We may create a model that fits our training data very well but does not score well on the test set, suggesting that it won't predict well given new data. With a test set, we can understand how our model performs on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Scale the data\n",
    "\n",
    "Make sure to...\n",
    "* instantiate a `StandardScaler` object\n",
    "* `fit` the scaler on your training data\n",
    "* `transform` both your training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling\n",
    "\n",
    "Now that you've completed your EDA, you can now use your training data to build a model to predict home price from your features! As far as regression methods, you've learned a few, including ordinary least squares (a.k.a. `LinearRegression`), `Lasso`, `Ridge`, and `ElasticNet`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Benchmarking\n",
    "\n",
    "As we get started with modeling we should have some basis for comparison to get a sense of what a \"good\" model is for this task. \n",
    "\n",
    "For this task, as we will be focusing on linear models, we will use the most naive of the linear models, the Linear Regression as our benchmark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a results `list` to hold your results. After each model fit and score, you will add a dictionary of your results to this list using `.append()`. This will give you a list of dictionaries ... perfect for a DataFrame!\n",
    "\n",
    "This is the pattern you will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_results = list()\n",
    "result_1 = {'name':'test1','dataset' : 'train','preprocessing': 'raw','score': '1 bajillion'}\n",
    "example_results.append(result_1)\n",
    "result_2 = {'name':'test1','dataset' : 'train','preprocessing': 'scaled','score': '20 bajillion'}\n",
    "example_results.append(result_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we pass the results list to pass to a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(example_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a convenient tool for manipulating our results and tracking our work ... our old friend, Pandas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a new results list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a new `LinearRegression` model and save it as `benchmark_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benchmark_raw = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the `benchmark_raw` model against the raw training data. \n",
    "- Score the `benchmark_raw` model against both the raw training set and the raw testing set. \n",
    "- Apprend a results dictionary to the `results` list. \n",
    "\n",
    "You could do this by\n",
    "\n",
    "    results.append({'name':'benchmark',\n",
    "                    'model': benchmark_raw,\n",
    "                    'dataset' : 'train',\n",
    "                    'preprocessing': 'raw',\n",
    "                    'score': raw_train_score})\n",
    "                    \n",
    "Of course you can store a model in a dictionary!                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "benchmark_raw.fit(X_train, y_train)\n",
    "raw_train_score = benchmark_raw.score(X_train, y_train)\n",
    "raw_test_score = benchmark_raw.score(X_test, y_test)\n",
    "\n",
    "results.append({'name':'benchmark',\n",
    "                'model':benchmark_raw,\n",
    "                'dataset' : 'train',\n",
    "                'preprocessing': 'raw',\n",
    "                'score': raw_train_score})\n",
    "results.append({'name':'benchmark',\n",
    "                'model':benchmark_raw,\n",
    "                'dataset' : 'test',\n",
    "                'preprocessing': 'raw',\n",
    "                'score': raw_test_score})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaled Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the `benchmark_scaled` model against the scaled training data. \n",
    "- Score the `benchmark_scaled` model against both the scaled training set and the scaled testing set. \n",
    "- Write the results to the results `list`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a DataFrame to display your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Naive Regularization\n",
    "\n",
    "Next, prepare a series of fits using the three regularized linear regression models with their default settings.\n",
    "\n",
    "Perform each of these against both the raw and the scaled data. In this section, you should be fitting six models.\n",
    "\n",
    "- A naive Ridge Regression against the raw data\n",
    "- A naive Lasso Regression against the raw data\n",
    "- A naive ElasticNet Regression against the raw data\n",
    "- A naive Ridge Regression against the scaled data\n",
    "- A naive Lasso Regression against the scaled data\n",
    "- A naive ElasticNet Regression against the scaled data\n",
    "\n",
    "**NOTE:** By \"naive\" we mean using all of the default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we see warnings here. As we are in an exploration phase with our model, this is acceptable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a DataFrame to store your `results` as `results_df`. By this we mean, save the `results` list into a new dataframe so that you can manipulate the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the raw test results using pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do this using pandas indexing as follows\n",
    "\n",
    "    results_df[(results_df.preprocessing == 'raw') & \n",
    "               (results_df.dataset == 'test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the scaled test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are your benchmark results. You will refer to these for analysis during the next phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the Benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the Ridge models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the Lasso models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the Elasticnet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are your observations? Add them to this markdown cell.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Cross-validated models\n",
    "\n",
    "Import the Cross-Validation Models for each of the Regularized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_results = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the cross-validation using an `np.logspace(-2,4,7)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the raw test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display just the scaled test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Model Selection\n",
    "\n",
    "Interpret Regression Metrics for each of your models. Choose one of the following:\n",
    "\n",
    "* R2\n",
    "* MSE / RMSE\n",
    "* MAE\n",
    "\n",
    "What are your top 3 performing models? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the bias / variance tradeoff\n",
    "\n",
    "Why do regularized models perform better on your test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpreting coefficients\n",
    "\n",
    "For your best model, \n",
    "\n",
    "* plot relevant coefficients using the `plot_coef` functoin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_coef(model, top_n = 10):\n",
    "    '''\n",
    "    Plots the magnitude of top and bottom n coefficients\n",
    "    '''\n",
    "    cols = X_train.columns\n",
    "    coef = model.coef_\n",
    "    zipped = list(zip(cols, coef))\n",
    "    zipped.sort(key=lambda x: x[1], reverse = True)\n",
    "    top_10 = pd.DataFrame(zipped).head(top_n)\n",
    "    bottom_10 = pd.DataFrame(zipped).tail(top_n)\n",
    "    return pd.concat([top_10, bottom_10], axis=0).plot.barh(x = 0, y = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot your coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which features add / take away most value from a home?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Informing Business Value\n",
    "\n",
    "Interpreting our work for a non-technical audience is a vital skill that every good Data Scientist must cultivate.  At the end of the day, our work must be informative to business process so connecting our detailed efforts to a high level strategy is critical.\n",
    "\n",
    "We've established a few businesses cases that you should assert some explanation and advise best strategy through a model of your choice.  Also call out any exploratory analysis and reasoning for any recommendation.\n",
    "\n",
    "##### For each question:\n",
    "* Plot relevant data\n",
    "* Fit a new model or use a previous  model\n",
    "* Plot relevant coefficients\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Case 1: Which features add / take away most value from a home?\n",
    "\n",
    "You just explained which coeffients add / take away most value, technically, but can you explain this in a non-technical manner?  Also, emphasize _why_ in your explanation.\n",
    "\n",
    "- Choose a few examples and explain why the coefficients describe the target value of the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Case 2: Can you identify any abnormally priced houses?\n",
    "We might consider these being properties that are over or under predicted by price. Can you make sense of when and why these are over and under predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Case 3:  Which houses are good investments?\n",
    "\n",
    "Which criteria would you look at?  How sure can you be of your assumptions?  Give precise metrics but also give a concise recommendation that is non-technical that communicates the risks of your anlaysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (Optional) Case 4:  Which houses are good investments (extended)?\n",
    "One idea that is common in the real-estate invement community is called \"flipping\".  This usually entails buying a property with \"changable\" charactaristics that can be upgraded.  Examples of changable or \"upgradable\" features include:  A garage, a kitchen, etc.\n",
    "\n",
    "Can you give us an idea of investments opportunities considering \"upgradable\" features?  You will have to explore this idea on your own and possibly do a little research for subject matter expertise.\n",
    "\n",
    "- Some features of a house are worth more than others\n",
    "- Some features can't be upgraded (ie: square footage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
